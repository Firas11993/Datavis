{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import re\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting intericite data\n",
    "times = pd.read_csv(DATA_DIR + \"/export-intercites-gtfs-last/stop_times.txt\")\n",
    "stops = pd.read_csv(DATA_DIR + \"/export-intercites-gtfs-last/stops.txt\")\n",
    "stops = stops[pd.notnull(stops[\"stop_name\"])]\n",
    "#Extracting ter data\n",
    "stops_ter = pd.read_csv(DATA_DIR + \"/ter/stops.txt\")\n",
    "stops_ter = stops_ter[pd.notnull(stops_ter[\"stop_name\"])]\n",
    "stop_times_ter = pd.read_csv(DATA_DIR + \"/ter/stop_times.txt\")\n",
    "# Prices\n",
    "prices_intercity = pd.read_csv(DATA_DIR + '/_intercity_prices.csv')\n",
    "prices_ter = pd.read_csv(DATA_DIR + '/bareme-de-prix-ter.csv', sep=';')\n",
    "prices_ter = prices_ter[prices_ter.Classe == '2 nde'][['Km', 'Plein tarif']]\n",
    "prices_ter = prices_ter.sort_values(by='Km')\n",
    "# Stations\n",
    "stations = pd.read_csv('./data/_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix times which hours exceeds 24\n",
    "def fix_times(time):\n",
    "    if int(time.split(\":\")[0]) >= 24:\n",
    "        return \"{}:\".format(int(time.split(\":\")[0]) - 24) + \":\".join(time.split(\":\")[1:])\n",
    "    return time\n",
    "\n",
    "def compute_duration(arrival_list, departure_list):\n",
    "    durations = []\n",
    "    for i in range(len(arrival_list) -1):\n",
    "        durations.append((datetime.strptime(arrival_list[i+1], \"%H:%M:%S\") - datetime.strptime(departure_list[i], \"%H:%M:%S\")).seconds / 60)\n",
    "    return durations\n",
    "\n",
    "def get_price(start, stop):\n",
    "    prices = []\n",
    "    tmp = prices_intercity[(prices_intercity.Origin == start) & (prices_intercity.Destination == stop)]\n",
    "    if not tmp.empty:\n",
    "        prices.append(tmp.iloc[0].Price)\n",
    "    tmp = prices_intercity[(prices_intercity.Destination == start) & (prices_intercity.Origin == stop)]\n",
    "    if not tmp.empty:\n",
    "        prices.append(tmp.iloc[0].Price)\n",
    "    if not prices:\n",
    "        return 144\n",
    "    return min(prices)\n",
    "\n",
    "def compute_price(dests_list):\n",
    "    prices = []\n",
    "    for i in range(len(dests_list) - 1):\n",
    "        start = dests_list[i]\n",
    "        stop = dests_list[i + 1]\n",
    "        price = get_price(start, stop)\n",
    "        prices.append(price)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix time for intercite.\n",
    "times[\"arrival_time\"] = times[\"arrival_time\"].apply(fix_times)\n",
    "times[\"departure_time\"] = times[\"departure_time\"].apply(fix_times)\n",
    "# Fix time for TER.\n",
    "stop_times_ter[\"arrival_time\"] = stop_times_ter[\"arrival_time\"].apply(fix_times)\n",
    "stop_times_ter[\"departure_time\"] = stop_times_ter[\"departure_time\"].apply(fix_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_1 = times.columns\n",
    "cols_2 = stops.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations to apply for station names.\n",
    "NORMALIZATIONS = {'ç': 'c',\n",
    "                  'é': 'e',\n",
    "                  'è': 'e',\n",
    "                  'ë': 'e',\n",
    "                  'ô': 'o',\n",
    "                  'â': 'a',\n",
    "                  'î': 'i',\n",
    "                  'ê': 'e',\n",
    "                  '\\\\(': '',\n",
    "                  '\\\\)': '',\n",
    "                  'û': 'u',\n",
    "                  '-': ' '}\n",
    "NORMALIZATIONS_REGEX = {re.compile(k): v for k, v in NORMALIZATIONS.items()}\n",
    "NORMALIZATIONS['('] = NORMALIZATIONS['\\\\(']\n",
    "NORMALIZATIONS[')'] = NORMALIZATIONS['\\\\)']\n",
    "del NORMALIZATIONS['\\\\(']\n",
    "del NORMALIZATIONS['\\\\)']\n",
    "WHITESPACE_REGEX = re.compile(' +')\n",
    "PARAN_REGEX = re.compile(' *\\([^)]*\\)$')\n",
    "# Some stations are spelled quite differently, or are ambiguous (had to resort to googling to figure out which is\n",
    "# which exactly). We have to define these manually.\n",
    "REPLACEMENTS = {'AEROPORT CDG 2 TGV ROISSY': 'Roissy-Aéroport-Charles-de-Gaulle 2-TGV (TGV)',\n",
    "                'AEROPORT CDG2 TGV ROISSY': 'Roissy-Aéroport-Charles-de-Gaulle 2-TGV (TGV)',\n",
    "                'Bâle': 'Bâle-St-Jean',\n",
    "                'MASSY PALAISEAU': 'Massy-Palaiseau-Grande-Ceinture',\n",
    "                'LILLE EUROPE-147322': 'Lille-Europe',\n",
    "                'RUFFEC CHARENTE': 'Ruffec',\n",
    "                'MOUTIERS SALINS BRIDES': 'Moûtiers-Salins-Brides-les-Bains',\n",
    "                'MANTES LA J. TGV': 'Mantes-la-Jolie',\n",
    "                'CLUSES  74': 'Cluses',\n",
    "                'STRASBOURG': 'Strasbourg-Ville',\n",
    "                'SAUMUR': 'Saumur-Rive-Droite',\n",
    "                'PARIS MONTPARNAS VAUGIRARD BLS': 'Paris-Montparnasse',\n",
    "                'PARIS MONTPARNASSE 3 VAUGIRARD': 'Paris-Montparnasse',\n",
    "                'PLOUARET TREGOR': 'Plouaret',\n",
    "                'plouaret tregor': 'Plouaret',\n",
    "                'Saint Malo': 'St-Malo',\n",
    "                'CONFLANS FDO TGV': 'Conflans-Fin-d\\'Oise',\n",
    "                'MULHOUSE VILLE': 'Mulhouse-Ville',\n",
    "                'MULHOUSE': 'Mulhouse-Ville',\n",
    "                'SAINT MICHEL VALLOIRE': 'St-Michel-Valloire',\n",
    "                'JUVISY TGV': 'Juvisy',\n",
    "                'Facture': 'Facture-Biganos',\n",
    "                'Saint Maixent': 'St-Maixent (Deux-Sèvres)',\n",
    "                'St maixent': 'St-Maixent (Deux-Sèvres)',\n",
    "                'Vendôme Gare TGV': 'Vendôme',\n",
    "                'saint nazaire': 'St-Nazaire',\n",
    "                'Saint Brieuc': 'St-Brieuc',\n",
    "                'PARIS MONTPARNASSE 1 ET 2': 'Paris-Montparnasse',\n",
    "                'Dol de Bretagne': 'Dol',\n",
    "                'DOL DE BRETAGNE': 'Dol',\n",
    "                'LYON SAINT EXUPERY TGV': 'Lyon-St-Exupéry-TGV',\n",
    "                'MONTPELLIER': 'Montpellier (CNM)',\n",
    "                'AVIGNON SUD': 'Avignon-Centre',\n",
    "                'Angers': 'Angers-St-Laud',\n",
    "                'VILLENEUVE LES AVIGNONS': 'Villeneuve-lès-Avignon'}\n",
    "# Some common suffixes which are missing in many cases, so we try using them to get a match when all else fails.\n",
    "SUFFIXES = ['-tgv', '-voyageurs']\n",
    "MEM = {}\n",
    "UNKNOWNS = set()\n",
    "\n",
    "def _from_name_get_matches(search, pattern):\n",
    "    pattern = pattern.strip()\n",
    "    if pattern in REPLACEMENTS:\n",
    "        pattern = REPLACEMENTS[pattern]\n",
    "    pattern = pattern.lower()\n",
    "    for pat, repl in NORMALIZATIONS.items():\n",
    "        pattern = pattern.replace(pat, repl)\n",
    "    pattern = re.sub(WHITESPACE_REGEX, ' ', pattern)\n",
    "    pattern = pattern.strip()\n",
    "    return stations[search == pattern]\n",
    "\n",
    "def _from_name_complex(name, try_suffixes=False):\n",
    "    search = stations.Name.str.lower()\n",
    "    for pat, repl in NORMALIZATIONS_REGEX.items():\n",
    "        search = search.replace(pat, repl)\n",
    "    pattern = name\n",
    "    if try_suffixes:\n",
    "        orig_pattern = pattern\n",
    "        for suffix in SUFFIXES:\n",
    "            pattern = orig_pattern + suffix\n",
    "            match = _from_name_get_matches(search, pattern)\n",
    "            if not match.empty:\n",
    "                return match\n",
    "    else:\n",
    "        return _from_name_get_matches(search, pattern)\n",
    "\n",
    "TRIMMINGS = ['-Centre', '-Carrefour', '-Mairie', 'Aéroport', '-Ctre', '-Gare-?.*', r' *\\([^)]*\\)']\n",
    "TRIMMINGS = [re.compile(trimming + '$') for trimming in TRIMMINGS]\n",
    "def _from_name(name, rec=False):\n",
    "    if isinstance(name, list):\n",
    "        return [_from_name(n) for n in name]\n",
    "    elif isinstance(name, str):\n",
    "        name = name.replace('Gare de ', '')\n",
    "    else:\n",
    "        return None\n",
    "    match = _from_name_complex(name)\n",
    "    if not match.empty:\n",
    "        return match.Name.iloc[0]\n",
    "    else:\n",
    "        match = _from_name_complex(name, try_suffixes=True)\n",
    "        if match is not None and not match.empty:\n",
    "            return match.Name.iloc[0]\n",
    "        elif name.endswith('-') or name.endswith('.'):\n",
    "            return _from_name(name[:-1])\n",
    "        elif rec:\n",
    "            return None\n",
    "        else:\n",
    "            for trimming in TRIMMINGS:\n",
    "                name = re.sub(trimming, '', name)\n",
    "            return _from_name(name, rec=True)\n",
    "\n",
    "def compute_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6373.0\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def get_nearest_name(lat, lon):\n",
    "    min_dist = 999999999\n",
    "    name = None\n",
    "    for _, station in stations.iterrows():\n",
    "        dist = compute_distance(lat, lon, station.Latitude, station.Longitude)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            name = station.Name\n",
    "    return name\n",
    "\n",
    "def fix_names(names, stop_lats, stop_lons):\n",
    "    # print('.', end='')\n",
    "    result = []\n",
    "    for i, name in enumerate(names):\n",
    "        if name in MEM:\n",
    "            fixed_name = MEM[name]\n",
    "        else:\n",
    "            fixed_name = _from_name(name)\n",
    "            MEM[name] = fixed_name\n",
    "        if not fixed_name:\n",
    "            stop_lat = stop_lats[i]\n",
    "            stop_lon = stop_lons[i]\n",
    "            # fixed_name = get_nearest_name(stop_lat, stop_lon)\n",
    "            UNKNOWNS.add(name)\n",
    "        result.append(fixed_name)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 8108/8108 [00:00<00:00, 15292.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.merge(times, stops, how=\"left\", left_on=times.stop_id, right_on=stops.stop_id).rename(columns={\"key_0\": \"stop_id\"})[[cols_1[0], cols_1[1], cols_1[2], cols_2[0], cols_2[1], cols_2[3], cols_2[4]]]\n",
    "timetable = table.groupby(\"trip_id\").agg(list).reset_index()\n",
    "\n",
    "timetable[\"durations\"] = timetable[[\"arrival_time\", \"departure_time\"]].apply(\n",
    "    lambda x: compute_duration(x[\"arrival_time\"], x[\"departure_time\"]), axis=1)\n",
    "\n",
    "timetable[\"stop_name\"] = timetable[[\"stop_name\", \"stop_lat\", \"stop_lon\"]].swifter.progress_bar(True).apply(\n",
    "    lambda x: fix_names(x[\"stop_name\"], x[\"stop_lat\"], x[\"stop_lon\"]))\n",
    "len(UNKNOWNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 8108/8108 [02:03<00:00, 65.42it/s] \n"
     ]
    }
   ],
   "source": [
    "timetable[\"prices\"] = timetable[[\"stop_name\"]].swifter.progress_bar(True).apply(lambda x: compute_price(x[\"stop_name\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unknown_stops(row):\n",
    "    to_remove = []\n",
    "    for i, stop in enumerate(row.stop_name):\n",
    "        if not stop:\n",
    "            to_remove.append(i)\n",
    "    if len(row.arrival_time) != len(row.stop_name):\n",
    "        print('This should not happen')\n",
    "        print(row)\n",
    "        return row\n",
    "    for i in sorted(to_remove, reverse=True):\n",
    "        del row.arrival_time[i]\n",
    "        del row.departure_time[i]\n",
    "        del row.stop_name[i]\n",
    "        del row.stop_lat[i]\n",
    "        del row.stop_lon[i]\n",
    "        if i > 0:\n",
    "            tmp_dur = row.durations[i - 1]\n",
    "            tmp_price = row.durations[i - 1]\n",
    "            del row.durations[i - 1]\n",
    "            del row.prices[i - 1]\n",
    "            if i < len(row.durations):\n",
    "                row.durations[i - 1] += tmp_dur\n",
    "                row.prices[i - 1] += tmp_price\n",
    "    return row\n",
    "\n",
    "timetable.apply(remove_unknown_stops, axis=1)\n",
    "timetable.drop(timetable[timetable.stop_name.str.len() <= 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>durations</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCESN001001F0100459990</td>\n",
       "      <td>[08:21:00, 11:06:00, 11:26:00, 11:52:00, 12:17...</td>\n",
       "      <td>[08:21:00, 11:09:00, 11:29:00, 12:00:00, 12:20...</td>\n",
       "      <td>[StopPoint:OCECorail Intercité-87113001, StopP...</td>\n",
       "      <td>[Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...</td>\n",
       "      <td>[48.87656977, 48.68978225, 48.58799369, 48.737...</td>\n",
       "      <td>[2.35915061, 6.17427169, 6.49703457, 7.0527805...</td>\n",
       "      <td>[165.0, 17.0, 23.0, 17.0]</td>\n",
       "      <td>[49.0, 7.4, 9.6, 5.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCESN001001F0100659999</td>\n",
       "      <td>[07:06:00, 10:26:00, 10:50:00, 11:14:00, 11:31...</td>\n",
       "      <td>[07:06:00, 10:32:00, 10:52:00, 11:16:00, 11:33...</td>\n",
       "      <td>[StopPoint:OCECorail Intercité-87113001, StopP...</td>\n",
       "      <td>[Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...</td>\n",
       "      <td>[48.87656977, 48.68978225, 48.58799369, 48.737...</td>\n",
       "      <td>[2.35915061, 6.17427169, 6.49703457, 7.0527805...</td>\n",
       "      <td>[200.0, 18.0, 22.0, 15.0]</td>\n",
       "      <td>[49.0, 7.4, 9.6, 5.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCESN001001F0100759984</td>\n",
       "      <td>[08:21:00, 11:06:00, 11:26:00, 11:52:00, 12:17...</td>\n",
       "      <td>[08:21:00, 11:09:00, 11:29:00, 12:00:00, 12:20...</td>\n",
       "      <td>[StopPoint:OCECorail Intercité-87113001, StopP...</td>\n",
       "      <td>[Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...</td>\n",
       "      <td>[48.87656977, 48.68978225, 48.58799369, 48.737...</td>\n",
       "      <td>[2.35915061, 6.17427169, 6.49703457, 7.0527805...</td>\n",
       "      <td>[165.0, 17.0, 23.0, 17.0]</td>\n",
       "      <td>[49.0, 7.4, 9.6, 5.9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  trip_id                                       arrival_time  \\\n",
       "0  OCESN001001F0100459990  [08:21:00, 11:06:00, 11:26:00, 11:52:00, 12:17...   \n",
       "1  OCESN001001F0100659999  [07:06:00, 10:26:00, 10:50:00, 11:14:00, 11:31...   \n",
       "2  OCESN001001F0100759984  [08:21:00, 11:06:00, 11:26:00, 11:52:00, 12:17...   \n",
       "\n",
       "                                      departure_time  \\\n",
       "0  [08:21:00, 11:09:00, 11:29:00, 12:00:00, 12:20...   \n",
       "1  [07:06:00, 10:32:00, 10:52:00, 11:16:00, 11:33...   \n",
       "2  [08:21:00, 11:09:00, 11:29:00, 12:00:00, 12:20...   \n",
       "\n",
       "                                             stop_id  \\\n",
       "0  [StopPoint:OCECorail Intercité-87113001, StopP...   \n",
       "1  [StopPoint:OCECorail Intercité-87113001, StopP...   \n",
       "2  [StopPoint:OCECorail Intercité-87113001, StopP...   \n",
       "\n",
       "                                           stop_name  \\\n",
       "0  [Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...   \n",
       "1  [Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...   \n",
       "2  [Paris-Est, Nancy-Ville, Lunéville, Sarrebourg...   \n",
       "\n",
       "                                            stop_lat  \\\n",
       "0  [48.87656977, 48.68978225, 48.58799369, 48.737...   \n",
       "1  [48.87656977, 48.68978225, 48.58799369, 48.737...   \n",
       "2  [48.87656977, 48.68978225, 48.58799369, 48.737...   \n",
       "\n",
       "                                            stop_lon  \\\n",
       "0  [2.35915061, 6.17427169, 6.49703457, 7.0527805...   \n",
       "1  [2.35915061, 6.17427169, 6.49703457, 7.0527805...   \n",
       "2  [2.35915061, 6.17427169, 6.49703457, 7.0527805...   \n",
       "\n",
       "                   durations                 prices  \n",
       "0  [165.0, 17.0, 23.0, 17.0]  [49.0, 7.4, 9.6, 5.9]  \n",
       "1  [200.0, 18.0, 22.0, 15.0]  [49.0, 7.4, 9.6, 5.9]  \n",
       "2  [165.0, 17.0, 23.0, 17.0]  [49.0, 7.4, 9.6, 5.9]  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable.to_csv(\"./data/export-intercites-gtfs-last/timetable_intercity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 31984/31984 [04:58<00:00, 107.17it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_ter = pd.merge(stop_times_ter,stops_ter,how='left', left_on=stop_times_ter.stop_id, right_on=stops_ter.stop_id) \\\n",
    "            [['trip_id', 'arrival_time', 'departure_time', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "\n",
    "timetable_ter = merged_ter.groupby(\"trip_id\").agg(list).reset_index()\n",
    "\n",
    "timetable_ter[\"durations\"] = timetable_ter[[\"arrival_time\",\"departure_time\"]].apply(\n",
    "    lambda x: compute_duration(x[\"arrival_time\"], x[\"departure_time\"]), axis=1)\n",
    "\n",
    "timetable_ter[\"stop_name\"] = timetable_ter[[\"stop_name\", \"stop_lat\", \"stop_lon\"]].swifter.progress_bar(True).apply(\n",
    "    lambda x: fix_names(x[\"stop_name\"], x[\"stop_lat\"], x[\"stop_lon\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_from_dist(dist):\n",
    "    try:\n",
    "        return prices_ter[prices_ter.Km > dist].iloc[0]['Plein tarif']\n",
    "    except IndexError:\n",
    "        return prices_ter[prices_ter.Km == 1300].iloc[0]['Plein tarif']\n",
    "\n",
    "def compute_price_ter(lat_list, lon_list):\n",
    "    prices = []\n",
    "    for i in range(len(lat_list) - 1):\n",
    "        start_lat = lat_list[i]\n",
    "        start_lon = lon_list[i]\n",
    "        stop_lat = lat_list[i + 1]\n",
    "        stop_lon = lon_list[i + 1]\n",
    "        dist = compute_distance(start_lat, start_lon, stop_lat, stop_lon)\n",
    "        price = get_price_from_dist(dist)\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "timetable_ter[\"prices\"] = timetable_ter[[\"stop_lat\", \"stop_lon\"]].apply(\n",
    "    lambda x: compute_price_ter(x[\"stop_lat\"], x[\"stop_lon\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable_ter.apply(remove_unknown_stops, axis=1)\n",
    "timetable_ter.drop(timetable_ter[timetable_ter.stop_name.str.len() <= 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>durations</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>OCESN002100R0100260086</td>\n",
       "      <td>[06:25:00, 06:33:00, 06:40:00, 06:48:00]</td>\n",
       "      <td>[06:25:00, 06:34:00, 06:41:00, 06:48:00]</td>\n",
       "      <td>[Provins, Champbenoist-Poigny, Ste-Colombe-Sep...</td>\n",
       "      <td>[48.55569426, 48.54535739999999, 48.53017483, ...</td>\n",
       "      <td>[3.30284529, 3.28705609, 3.25721747, 3.24968453]</td>\n",
       "      <td>[8.0, 6.0, 7.0]</td>\n",
       "      <td>[1.2, 1.4, 1.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>OCESN002100R0100360088</td>\n",
       "      <td>[06:30:00, 06:33:00, 06:40:00, 06:48:00]</td>\n",
       "      <td>[06:30:00, 06:34:00, 06:41:00, 06:48:00]</td>\n",
       "      <td>[Provins, Champbenoist-Poigny, Ste-Colombe-Sep...</td>\n",
       "      <td>[48.55569426, 48.54535739999999, 48.53017483, ...</td>\n",
       "      <td>[3.30284529, 3.28705609, 3.25721747, 3.24968453]</td>\n",
       "      <td>[3.0, 6.0, 7.0]</td>\n",
       "      <td>[1.2, 1.4, 1.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>OCESN002101R0100160094</td>\n",
       "      <td>[06:44:00, 06:51:00, 06:57:00, 07:02:00]</td>\n",
       "      <td>[06:44:00, 06:52:00, 06:58:00, 07:02:00]</td>\n",
       "      <td>[Longueville, Ste-Colombe-Septveilles, Champbe...</td>\n",
       "      <td>[48.51351115, 48.53017483, 48.54535739999999, ...</td>\n",
       "      <td>[3.24968453, 3.25721747, 3.28705609, 3.30284529]</td>\n",
       "      <td>[7.0, 5.0, 4.0]</td>\n",
       "      <td>[1.2, 1.4, 1.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    trip_id                              arrival_time  \\\n",
       "223  OCESN002100R0100260086  [06:25:00, 06:33:00, 06:40:00, 06:48:00]   \n",
       "224  OCESN002100R0100360088  [06:30:00, 06:33:00, 06:40:00, 06:48:00]   \n",
       "225  OCESN002101R0100160094  [06:44:00, 06:51:00, 06:57:00, 07:02:00]   \n",
       "\n",
       "                               departure_time  \\\n",
       "223  [06:25:00, 06:34:00, 06:41:00, 06:48:00]   \n",
       "224  [06:30:00, 06:34:00, 06:41:00, 06:48:00]   \n",
       "225  [06:44:00, 06:52:00, 06:58:00, 07:02:00]   \n",
       "\n",
       "                                             stop_name  \\\n",
       "223  [Provins, Champbenoist-Poigny, Ste-Colombe-Sep...   \n",
       "224  [Provins, Champbenoist-Poigny, Ste-Colombe-Sep...   \n",
       "225  [Longueville, Ste-Colombe-Septveilles, Champbe...   \n",
       "\n",
       "                                              stop_lat  \\\n",
       "223  [48.55569426, 48.54535739999999, 48.53017483, ...   \n",
       "224  [48.55569426, 48.54535739999999, 48.53017483, ...   \n",
       "225  [48.51351115, 48.53017483, 48.54535739999999, ...   \n",
       "\n",
       "                                             stop_lon        durations  \\\n",
       "223  [3.30284529, 3.28705609, 3.25721747, 3.24968453]  [8.0, 6.0, 7.0]   \n",
       "224  [3.30284529, 3.28705609, 3.25721747, 3.24968453]  [3.0, 6.0, 7.0]   \n",
       "225  [3.24968453, 3.25721747, 3.28705609, 3.30284529]  [7.0, 5.0, 4.0]   \n",
       "\n",
       "              prices  \n",
       "223  [1.2, 1.4, 1.2]  \n",
       "224  [1.2, 1.4, 1.2]  \n",
       "225  [1.2, 1.4, 1.2]  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetable_ter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable_ter.to_csv(\"./data/ter/timetable_ter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable_ter_copy = timetable_ter.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
